{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import Bunch\n",
    "import numpy as np\n",
    "\n",
    "data = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "target = np.array([1, 0, 1])\n",
    "feature_names = ['feature1', 'feature2', 'feature3']\n",
    "target_names = ['class0', 'class1']\n",
    "\n",
    "# Create the Bunch object\n",
    "my_bunch = Bunch(data=data, target=target, feature_names=feature_names, target_names=target_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1]\n",
      "[0.66665234 0.66666141 0.66667048]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Load the iris dataset\n",
    "X = my_bunch.data\n",
    "y = my_bunch.target\n",
    "\n",
    "# Fit a model\n",
    "model = LogisticRegression()\n",
    "model.fit(X, y)\n",
    "y_pred = model.predict(X)\n",
    "print(y_pred)\n",
    "y_pred_proba = model.predict_proba(X)[:, 1]\n",
    "print(y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1]\n",
      "[0.76946551 0.45540594 0.77508227]\n",
      "[1 0 1]\n",
      "[0.76946551 0.45540594 0.77508227]\n",
      "[1 0 1]\n",
      "[0.76946551 0.45540594 0.77508227]\n",
      "[0.44398633 0.48498809 0.45298247] -0.324556726081456\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data_list = [[1.1, 1.12, 1.1], [0.13, 0.06, 0.13], [1.11, 1.13, 1.15]]\n",
    "target_list = [1, 0, 1] \n",
    "data_array = np.array(data_list)\n",
    "target_array = np.array(target_list)\n",
    "data_frame = pd.DataFrame(data_list, columns=['feature1', 'feature2', 'feature3'])\n",
    "data_frame['target'] = target_list\n",
    "\n",
    "\n",
    "# Fit a model use the list\n",
    "logit = LogisticRegression()\n",
    "logit.fit(data_list, target_list)\n",
    "print(logit.predict(data_list))\n",
    "print(logit.predict_proba(data_list)[:, 1])\n",
    "\n",
    "# Fit a model use the array\n",
    "logit1 = LogisticRegression()\n",
    "logit1.fit(data_array, target_array)\n",
    "print(logit1.predict(data_array))\n",
    "print(logit1.predict_proba(data_array)[:, 1])\n",
    "\n",
    "# Fit a model use the DataFrame\n",
    "logit2 = LogisticRegression()\n",
    "logit2.fit(data_frame[['feature1', 'feature2', 'feature3']], data_frame['target'])\n",
    "print(logit2.predict(data_frame[['feature1', 'feature2', 'feature3']]))\n",
    "print(logit2.predict_proba(data_frame[['feature1', 'feature2', 'feature3']])[:, 1])\n",
    "\n",
    "coef2 = logit2.coef_[0]\n",
    "intercept2 = logit2.intercept_[0]\n",
    "print(coef2, intercept2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Coefficient  Standard Error  Wald Statistic  p-value\n",
      "feature1      0.443986             NaN             NaN      NaN\n",
      "feature2      0.484988             NaN             NaN      NaN\n",
      "feature3      0.452982             NaN             NaN      NaN\n",
      "intercept    -0.324557             NaN             NaN      NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tiang\\AppData\\Local\\Temp\\ipykernel_12808\\1800048874.py:8: RuntimeWarning: invalid value encountered in sqrt\n",
      "  standard_errors = np.sqrt(np.diag(cov_matrix))\n"
     ]
    }
   ],
   "source": [
    "# Calculate the standard errors of the coefficients\n",
    "# The covariance matrix of the coefficients is the inverse of the Hessian matrix\n",
    "from scipy import stats\n",
    "\n",
    "X_train = data_frame[['feature1', 'feature2', 'feature3']]\n",
    "X_train = np.hstack((X_train, np.ones((X_train.shape[0], 1))))\n",
    "cov_matrix = np.linalg.inv(np.dot(X_train.T, X_train))\n",
    "standard_errors = np.sqrt(np.diag(cov_matrix))\n",
    "\n",
    "# Perform the Wald test\n",
    "wald_statistics = (np.append(coef2, intercept2) / standard_errors) ** 2\n",
    "p_values = stats.chi2.sf(wald_statistics, df=1)\n",
    "\n",
    "# Create a DataFrame to display the results\n",
    "results = pd.DataFrame({\n",
    "    'Coefficient': np.append(coef2, intercept2),\n",
    "    'Standard Error': standard_errors, \n",
    "    'Wald Statistic': wald_statistics, \n",
    "    'p-value': p_values\n",
    "}, index=['feature1', 'feature2', 'feature3', 'intercept'])\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.44398633 0.48498809 0.45298247]]\n",
      "[-0.32455673]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coef.</th>\n",
       "      <th>Std.Err</th>\n",
       "      <th>z</th>\n",
       "      <th>P&gt;|z|</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>const</th>\n",
       "      <td>-0.324557</td>\n",
       "      <td>3.352599e+07</td>\n",
       "      <td>-9.680751e-09</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature1</th>\n",
       "      <td>0.443986</td>\n",
       "      <td>4.559282e+08</td>\n",
       "      <td>9.738077e-10</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature2</th>\n",
       "      <td>0.484988</td>\n",
       "      <td>4.085453e+08</td>\n",
       "      <td>1.187110e-09</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature3</th>\n",
       "      <td>0.452982</td>\n",
       "      <td>9.476567e+06</td>\n",
       "      <td>4.780027e-08</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Coef.       Std.Err             z  P>|z|\n",
       "const    -0.324557  3.352599e+07 -9.680751e-09    1.0\n",
       "feature1  0.443986  4.559282e+08  9.738077e-10    1.0\n",
       "feature2  0.484988  4.085453e+08  1.187110e-09    1.0\n",
       "feature3  0.452982  9.476567e+06  4.780027e-08    1.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skorecard.linear_model import LogisticRegression as skorecard_logit\n",
    "sklogit = skorecard_logit(calculate_stats=True)\n",
    "sklogit.fit(data_frame[['feature1', 'feature2', 'feature3']], data_frame['target'])\n",
    "print(sklogit.coef_)\n",
    "print(sklogit.intercept_)\n",
    "sklogit.get_stats()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "[[1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "[[ 82. 173. 228.  10.]\n",
      " [173. 365. 481.  21.]\n",
      " [228. 481. 634.  28.]\n",
      " [ 10.  21.  28.   2.]]\n",
      "[[ 1.66913998e+14 -3.69399833e+13 -3.21514669e+13  3.42036881e+12]\n",
      " [ 2.38257967e+18  2.13365343e+17 -1.03126583e+18  2.84487125e+17]\n",
      " [-1.84114498e+18 -1.64859787e+17  7.96898921e+17 -2.19832204e+17]\n",
      " [ 7.58108705e+17  6.78856147e+16 -3.28132959e+17  9.05189415e+16]]\n",
      "[1.29195201e+07 4.61914866e+08 8.92691952e+08 3.00863659e+08]\n"
     ]
    }
   ],
   "source": [
    "Array1 = np.array([[1,2,3],[9,19,25]])\n",
    "print(Array1.shape[0])\n",
    "print(Array1.shape[1])\n",
    "print(np.ones((Array1.shape[1], 1)))\n",
    "Array2 = np.hstack((Array1, np.ones((Array1.shape[0], 1))))\n",
    "Array3 = np.dot(Array2.T, Array2)\n",
    "print(Array3)\n",
    "print(np.linalg.inv(Array3))\n",
    "print(np.sqrt(np.diag(np.linalg.inv(Array3))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.000000\n",
      "         Iterations: 35\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                 target   No. Observations:                    3\n",
      "Model:                          Logit   Df Residuals:                        0\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Sun, 09 Feb 2025   Pseudo R-squ.:                   1.000\n",
      "Time:                        21:49:51   Log-Likelihood:            -5.4052e-12\n",
      "converged:                      False   LL-Null:                       -1.9095\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.1481\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        -30.9048   3.68e+12  -8.39e-12      1.000   -7.22e+12    7.22e+12\n",
      "feature1      25.6297   5.01e+13   5.12e-13      1.000   -9.82e+13    9.82e+13\n",
      "feature2      31.2302   4.49e+13   6.96e-13      1.000    -8.8e+13     8.8e+13\n",
      "feature3      -3.9611   1.04e+12   -3.8e-12      1.000   -2.04e+12    2.04e+12\n",
      "==============================================================================\n",
      "\n",
      "Complete Separation: The results show that there iscomplete separation or perfect prediction.\n",
      "In this case the Maximum Likelihood Estimator does not exist and the parameters\n",
      "are not identified.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\Lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
      "d:\\anaconda3\\Lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
      "d:\\anaconda3\\Lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
      "d:\\anaconda3\\Lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
      "d:\\anaconda3\\Lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
      "d:\\anaconda3\\Lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
      "d:\\anaconda3\\Lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
      "d:\\anaconda3\\Lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
      "d:\\anaconda3\\Lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
      "d:\\anaconda3\\Lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
      "d:\\anaconda3\\Lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
      "d:\\anaconda3\\Lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
      "d:\\anaconda3\\Lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
      "d:\\anaconda3\\Lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
      "d:\\anaconda3\\Lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
      "d:\\anaconda3\\Lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
      "d:\\anaconda3\\Lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
      "d:\\anaconda3\\Lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
      "d:\\anaconda3\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "smlogit = sm.Logit(data_frame['target'], sm.add_constant(data_frame[['feature1', 'feature2', 'feature3']]))\n",
    "result = smlogit.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.589044\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  100\n",
      "Model:                          Logit   Df Residuals:                       96\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                 So, 09 Feb 2025   Pseudo R-squ.:                  0.1492\n",
      "Time:                        22:46:18   Log-Likelihood:                -58.904\n",
      "converged:                       True   LL-Null:                       -69.235\n",
      "Covariance Type:            nonrobust   LLR p-value:                 0.0001238\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -2.5450      0.761     -3.344      0.001      -4.037      -1.053\n",
      "feature1       1.3975      0.776      1.800      0.072      -0.124       2.919\n",
      "feature2       3.1100      0.827      3.760      0.000       1.489       4.731\n",
      "feature3       0.8287      0.833      0.995      0.320      -0.804       2.462\n",
      "==============================================================================\n",
      "Coefficients: const      -2.545015\n",
      "feature1    1.397545\n",
      "feature2    3.110040\n",
      "feature3    0.828747\n",
      "dtype: float64\n",
      "Standard Errors: const       0.761102\n",
      "feature1    0.776431\n",
      "feature2    0.827125\n",
      "feature3    0.833086\n",
      "dtype: float64\n",
      "P-values: const       0.000826\n",
      "feature1    0.071867\n",
      "feature2    0.000170\n",
      "feature3    0.319838\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Generate some example data\n",
    "np.random.seed(0)\n",
    "n_samples = 100\n",
    "X = np.random.rand(n_samples, 3)\n",
    "X = sm.add_constant(X)  # Add intercept term\n",
    "y = (X[:, 1] + X[:, 2] * 2 + np.random.randn(n_samples) > 1.5).astype(int)\n",
    "\n",
    "# Create a DataFrame for the independent variables\n",
    "data_frame = pd.DataFrame(X, columns=['const', 'feature1', 'feature2', 'feature3'])\n",
    "\n",
    "# Fit a logistic regression model using statsmodels\n",
    "logit_model = sm.Logit(y, data_frame)\n",
    "result = logit_model.fit()\n",
    "\n",
    "# Print the summary of the model\n",
    "print(result.summary())\n",
    "\n",
    "# Get the coefficients and intercept\n",
    "print(\"Coefficients:\", result.params)\n",
    "print(\"Standard Errors:\", result.bse)\n",
    "print(\"P-values:\", result.pvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.39545798 3.10830058 0.82937716]] [-2.54370352]\n"
     ]
    }
   ],
   "source": [
    "logit5 = LogisticRegression(fit_intercept=True, solver='lbfgs', penalty = None) \n",
    "logit5.fit(data_frame[['feature1', 'feature2', 'feature3']], y)\n",
    "print(logit5.coef_ , logit5.intercept_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.39545798 3.10830058 0.82937716]] [-2.54370352]\n",
      "             Coef.   Std.Err         z     P>|z|\n",
      "const    -2.543704  0.760960 -3.342757  0.000830\n",
      "feature1  1.395458  0.776272  1.797641  0.072234\n",
      "feature2  3.108301  0.826957  3.758720  0.000171\n",
      "feature3  0.829377  0.832969  0.995688  0.319402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "sklogit = skorecard_logit(calculate_stats=True, penalty=None)\n",
    "sklogit.fit(data_frame[['feature1', 'feature2', 'feature3']], y)\n",
    "print(sklogit.coef_, sklogit.intercept_)\n",
    "print(sklogit.get_stats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
